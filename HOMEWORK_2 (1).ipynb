{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "582ba4df",
   "metadata": {
    "id": "582ba4df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "db7b31da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#In this project, you are tasked to build a model(s) that predict a player's overall rating given the player's profile.\n",
    "#Demonstrate the data preparation & feature extraction process\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "WGtPSCyat0WI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WGtPSCyat0WI",
    "outputId": "3d3ef216-216e-48ac-a82a-a9a735e841e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12796\\1990246387.py:5: DtypeWarning: Columns (25,108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data22 = pd.read_csv(file22)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12796\\1990246387.py:7: DtypeWarning: Columns (108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "file = \"male_players (legacy).csv\"\n",
    "file22=\"players_22.csv\"\n",
    "data22 = pd.read_csv(file22)\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cL0timkzuW7v",
   "metadata": {
    "id": "cL0timkzuW7v"
   },
   "outputs": [],
   "source": [
    "# Step 2: Drop specified columns\n",
    "columns_to_drop = [\n",
    "    'player_id', 'dob', 'player_tags', 'club_contract_valid_until_year', 'player_url', 'club_jersey_number', 'club_name', 'fifa_update',\n",
    "    'long_name', 'short_name', 'league_id', 'player_face_url', 'nationality_id', 'preferred_foot', 'club_contract_valid_until_year',\n",
    "    'fifa_update_date', 'club_position', 'league_name', 'club_team_id', 'nation_team_id', 'player_traits', 'club_joined_date', 'league_level',\n",
    "    'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'ldm', 'cdm', 'rdm', 'lb', 'cb', 'nationality_name', 'real_face',\n",
    "    'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lwb', 'rwb', 'lcb', 'rcb', 'rb', 'gk', 'player_face_url', 'ls', 'st', 'body_type', 'fifa_version'\n",
    "]\n",
    "columns_to_drop22 = [\n",
    "    'sofifa_id', 'dob', 'player_tags', 'club_contract_valid_until', 'player_url', 'club_jersey_number', 'club_name','club_loaned_from','nation_position',\n",
    "    'long_name', 'short_name', 'player_face_url', 'nationality_id', 'preferred_foot','club_position', 'league_name', 'club_team_id', 'nation_team_id', 'player_traits', 'club_joined', 'league_level',\n",
    "    'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'ldm', 'cdm', 'rdm', 'lb', 'cb', 'nationality_name', 'real_face','nation_logo_url','nation_flag_url',\n",
    "    'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lwb', 'rwb', 'lcb', 'rcb', 'rb', 'gk', 'player_face_url', 'ls', 'st', 'body_type','club_logo_url','club_flag_url'\n",
    "]\n",
    "data = data.drop(columns=columns_to_drop, axis=1)\n",
    "data22=data22.drop(columns=columns_to_drop22, axis=1)\n",
    "\n",
    "# Step 3: Drop columns with 30% or more null values\n",
    "biased_threshold = 0.30 * len(data)\n",
    "data = data.loc[:, data.isna().sum() < biased_threshold]\n",
    "data22=data22.loc[:, data22.isna().sum() < biased_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ab1763d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ab1763d8",
    "outputId": "9850fd63-b786-440b-e491-dc8d7bb87e0f"
   },
   "outputs": [],
   "source": [
    "# Function to check for mixed data types in a column\n",
    "def check_mixed_types(column):\n",
    "    types = column.apply(lambda x: type(x)).unique()\n",
    "    return len(types) > 1\n",
    "\n",
    "#  Separate numeric data from non-numeric data\n",
    "numeric_data = data.select_dtypes(include=np.number)\n",
    "numeric_data22=data22.select_dtypes(include=np.number)\n",
    "non_numeric_data = data.select_dtypes(include=['object'])\n",
    "non_numeric_data22 = data22.select_dtypes(include=['object'])\n",
    "\n",
    "#  Impute missing values for numeric data with mean\n",
    "numeric_data = numeric_data.apply(lambda col: col.fillna(col.mean()))\n",
    "numeric_data22 = numeric_data22.apply(lambda col: col.fillna(col.mean()))\n",
    "\n",
    "# Impute missing values for non-numeric data with mode\n",
    "for column in non_numeric_data.columns:\n",
    "    mode = non_numeric_data[column].mode()[0]\n",
    "    non_numeric_data[column].fillna(mode, inplace=True)\n",
    "\n",
    "# Impute missing values for non-numeric22 data with mode\n",
    "for column in non_numeric_data22.columns:\n",
    "    mode = non_numeric_data22[column].mode()[0]\n",
    "    non_numeric_data22[column].fillna(mode, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "EJ0VKHiQv2Ke",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "EJ0VKHiQv2Ke",
    "outputId": "09bf6e41-4946-43cf-d8b9-14e60c4a0c91"
   },
   "outputs": [],
   "source": [
    "# Encode categorical columns using LabelEncoder\n",
    "label_encoders = {}\n",
    "for column in non_numeric_data.columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    non_numeric_data[column] = label_encoders[column].fit_transform(non_numeric_data[column])\n",
    "\n",
    "# Encode categorical columns for test data using the same LabelEncoders\n",
    "for column in non_numeric_data22.columns:\n",
    "    if column in label_encoders:\n",
    "        non_numeric_data22[column] = label_encoders[column].transform(non_numeric_data22[column])\n",
    "    else:\n",
    "        # Handle cases where the test data might have columns not present in the training data\n",
    "        print(f\"Warning: Column {column} not found in training data encoders and will be ignored.\")\n",
    "        non_numeric_data22 = non_numeric_data22.drop(columns=[column])\n",
    "    # Combine numeric data and label encoded data\n",
    "processed_data = pd.concat([numeric_data, non_numeric_data], axis=1)\n",
    "data22=pd.concat([numeric_data22, non_numeric_data22], axis=1)\n",
    "corr_matrix=processed_data.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "-MPtVliX4quU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MPtVliX4quU",
    "outputId": "233d18cc-46a5-4af0-9d43-6099d8ec0374"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movement_reactions',\n",
       " 'potential',\n",
       " 'passing',\n",
       " 'wage_eur',\n",
       " 'mentality_composure',\n",
       " 'value_eur',\n",
       " 'dribbling',\n",
       " 'attacking_short_passing',\n",
       " 'mentality_vision',\n",
       " 'international_reputation',\n",
       " 'skill_long_passing',\n",
       " 'power_shot_power',\n",
       " 'physic',\n",
       " 'age',\n",
       " 'skill_ball_control']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definers = []\n",
    "for col in processed_data.columns:\n",
    "    if col != 'overall':\n",
    "        if (corr_matrix.loc['overall', col] > 0.45) or (corr_matrix.loc['overall', col] < -0.45):\n",
    "            definers.append(col)\n",
    "correlation_dict = {col: corr_matrix.loc['overall', col] for col in definers}\n",
    "\n",
    "# Sort the definers list based on the correlation values with 'overall' in descending order\n",
    "sorted_definers = sorted(definers, key=lambda x: correlation_dict[x], reverse=True)\n",
    "sorted_definers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "v4YIQKOw7ViZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "v4YIQKOw7ViZ",
    "outputId": "4b2ec0c0-23ec-4048-8ebf-9428a743188e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>potential</th>\n",
       "      <th>value_eur</th>\n",
       "      <th>wage_eur</th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>weak_foot</th>\n",
       "      <th>skill_moves</th>\n",
       "      <th>international_reputation</th>\n",
       "      <th>...</th>\n",
       "      <th>defending_marking_awareness</th>\n",
       "      <th>defending_standing_tackle</th>\n",
       "      <th>defending_sliding_tackle</th>\n",
       "      <th>goalkeeping_diving</th>\n",
       "      <th>goalkeeping_handling</th>\n",
       "      <th>goalkeeping_kicking</th>\n",
       "      <th>goalkeeping_positioning</th>\n",
       "      <th>goalkeeping_reflexes</th>\n",
       "      <th>player_positions</th>\n",
       "      <th>work_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>100500000.0</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>27</td>\n",
       "      <td>169</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>412</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>79000000.0</td>\n",
       "      <td>375000.0</td>\n",
       "      <td>29</td>\n",
       "      <td>185</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>1128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>54500000.0</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>52500000.0</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>32</td>\n",
       "      <td>195</td>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>1838</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>63500000.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>28</td>\n",
       "      <td>193</td>\n",
       "      <td>92</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>87</td>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>719</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161578</th>\n",
       "      <td>46</td>\n",
       "      <td>61</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>18</td>\n",
       "      <td>180</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1643</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161579</th>\n",
       "      <td>46</td>\n",
       "      <td>58</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>19</td>\n",
       "      <td>188</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>721</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161580</th>\n",
       "      <td>46</td>\n",
       "      <td>58</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>19</td>\n",
       "      <td>181</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>289</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161581</th>\n",
       "      <td>46</td>\n",
       "      <td>70</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>17</td>\n",
       "      <td>175</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1694</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161582</th>\n",
       "      <td>46</td>\n",
       "      <td>63</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>17</td>\n",
       "      <td>180</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>203</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161583 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall  potential    value_eur  wage_eur  age  height_cm  weight_kg  \\\n",
       "0            93         95  100500000.0  550000.0   27        169         67   \n",
       "1            92         92   79000000.0  375000.0   29        185         80   \n",
       "2            90         90   54500000.0  275000.0   30        180         80   \n",
       "3            90         90   52500000.0  275000.0   32        195         95   \n",
       "4            90         90   63500000.0  300000.0   28        193         92   \n",
       "...         ...        ...          ...       ...  ...        ...        ...   \n",
       "161578       46         61     110000.0     700.0   18        180         73   \n",
       "161579       46         58     110000.0     750.0   19        188         83   \n",
       "161580       46         58     110000.0     500.0   19        181         73   \n",
       "161581       46         70     150000.0     500.0   17        175         68   \n",
       "161582       46         63     110000.0     500.0   17        180         70   \n",
       "\n",
       "        weak_foot  skill_moves  international_reputation  ...  \\\n",
       "0               3            4                         5  ...   \n",
       "1               4            5                         5  ...   \n",
       "2               2            4                         5  ...   \n",
       "3               4            4                         5  ...   \n",
       "4               4            1                         5  ...   \n",
       "...           ...          ...                       ...  ...   \n",
       "161578          3            2                         1  ...   \n",
       "161579          3            2                         1  ...   \n",
       "161580          2            2                         1  ...   \n",
       "161581          3            2                         1  ...   \n",
       "161582          3            2                         1  ...   \n",
       "\n",
       "        defending_marking_awareness  defending_standing_tackle  \\\n",
       "0                                25                         21   \n",
       "1                                22                         31   \n",
       "2                                29                         26   \n",
       "3                                25                         41   \n",
       "4                                25                         25   \n",
       "...                             ...                        ...   \n",
       "161578                           23                         21   \n",
       "161579                           50                         51   \n",
       "161580                           36                         45   \n",
       "161581                           19                         17   \n",
       "161582                           50                         45   \n",
       "\n",
       "        defending_sliding_tackle  goalkeeping_diving  goalkeeping_handling  \\\n",
       "0                             20                   6                    11   \n",
       "1                             23                   7                    11   \n",
       "2                             26                  10                     8   \n",
       "3                             27                  13                    15   \n",
       "4                             25                  87                    85   \n",
       "...                          ...                 ...                   ...   \n",
       "161578                        25                   9                    13   \n",
       "161579                        45                   6                    14   \n",
       "161580                        50                   8                     9   \n",
       "161581                        14                  13                    12   \n",
       "161582                        42                  13                     7   \n",
       "\n",
       "        goalkeeping_kicking  goalkeeping_positioning  goalkeeping_reflexes  \\\n",
       "0                        15                       14                     8   \n",
       "1                        15                       14                    11   \n",
       "2                        11                        5                    15   \n",
       "3                        10                        9                    12   \n",
       "4                        92                       90                    86   \n",
       "...                     ...                      ...                   ...   \n",
       "161578                   13                       12                     7   \n",
       "161579                    8                       13                    14   \n",
       "161580                    7                       14                     9   \n",
       "161581                   14                        7                    13   \n",
       "161582                    6                        6                    14   \n",
       "\n",
       "        player_positions  work_rate  \n",
       "0                    412          7  \n",
       "1                   1128          1  \n",
       "2                   1541          1  \n",
       "3                   1838          7  \n",
       "4                    719          8  \n",
       "...                  ...        ...  \n",
       "161578              1643          8  \n",
       "161579               721          8  \n",
       "161580               289          2  \n",
       "161581              1694          8  \n",
       "161582               203          8  \n",
       "\n",
       "[161583 rows x 52 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "wylLUlRlvbMP",
   "metadata": {
    "id": "wylLUlRlvbMP"
   },
   "outputs": [],
   "source": [
    "# scaling te data after label encoding\n",
    "overall=processed_data['overall']\n",
    "processed_data=processed_data[sorted_definers]\n",
    "scaler=StandardScaler()\n",
    "scaler_2=scaler.fit_transform(processed_data)\n",
    "scaler_2\n",
    "processed_data=pd.DataFrame(scaler_2,columns=processed_data.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tHGKqsjOl5GS",
   "metadata": {
    "id": "tHGKqsjOl5GS"
   },
   "source": [
    "TRAINING AND TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ynHhjW6rOw-G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ynHhjW6rOw-G",
    "outputId": "1ee12e00-d44a-4c68-adbe-4547d8a49fd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129266 train + 32317 test\n"
     ]
    }
   ],
   "source": [
    "# splitting data for train and test.\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(processed_data,test_size=0.2, random_state=42)  # splitt into two sets using 20 % 80%\n",
    "print(len(train_set), \"train +\", len(test_set), \"test\")  # splitting datset using 20 % 80%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5GmFQ4BHog1k",
   "metadata": {
    "id": "5GmFQ4BHog1k"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X = processed_data.copy()\n",
    "y=overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EI64ARHU69_d",
   "metadata": {
    "id": "EI64ARHU69_d"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "uDpQ1CQHnFaN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uDpQ1CQHnFaN",
    "outputId": "b15fbad1-5c77-47f0-e1e2-70b53e564645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor RMSE: 0.8363558688741984\n",
      "test score: 0.9858869672255272\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# getting best features\n",
    "forest=RandomForestRegressor(n_estimators=250,n_jobs=-1)\n",
    "forest=forest.fit(Xtrain, Ytrain)\n",
    "forest_predictions = forest.predict(Xtest)\n",
    "forest_score=forest.score(Xtest,Ytest)\n",
    "forest_rmse = np.sqrt(mean_squared_error(Ytest, forest_predictions))\n",
    "\n",
    "print(f'RandomForestRegressor RMSE: {forest_rmse}')\n",
    "\n",
    "print(f'test score: {forest_score}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "E1dkPl0G11hN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1dkPl0G11hN",
    "outputId": "3c7946ef-9676-430c-a64f-7c6b4b568636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor RMSE: 1.069101790872209\n",
      "test_score: 0.9769391003150766\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=250, random_state=42)\n",
    "gbr=gbr.fit(Xtrain, Ytrain)\n",
    "gbr_predictions = gbr.predict(Xtest)\n",
    "gbr_rmse = np.sqrt(mean_squared_error(Ytest, gbr_predictions))\n",
    "gbr_score=gbr.score(Xtest,Ytest)\n",
    "print(f'GradientBoostingRegressor RMSE: {gbr_rmse}')\n",
    "print(f'test_score: {gbr_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "Xyk5EQ5D2p2i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xyk5EQ5D2p2i",
    "outputId": "0cb3f8a0-002d-4a64-ac14-bb0411902c6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoostRegressor RMSE: 0.8857200425956522\n",
      "test_score: 0.9841718164802625\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(n_estimators=250, random_state=42, n_jobs=-1)\n",
    "xgb.fit(Xtrain, Ytrain)\n",
    "xgb_predictions = xgb.predict(Xtest)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(Ytest, xgb_predictions))\n",
    "xgb_score=xgb.score(Xtest,Ytest)\n",
    "print(f'XGBoostRegressor RMSE: {xgb_rmse}')\n",
    "print(f'test_score: {xgb_score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y_67x2ce8irg",
   "metadata": {
    "id": "y_67x2ce8irg"
   },
   "source": [
    "UTILIZING FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "njtE2CYl8h5l",
   "metadata": {
    "id": "njtE2CYl8h5l"
   },
   "outputs": [],
   "source": [
    "# Get feature importances for the forest regressor because it was the best model\n",
    "feature_importances = forest.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = Xtrain.columns\n",
    "\n",
    "# Create a dictionary of feature names and their importances\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "# Sort features by importance (from highest to lowest)\n",
    "sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Select the top 7 features based on importance\n",
    "selected_features = sorted_features[:7]\n",
    "\n",
    "# Extract the names of the selected features\n",
    "selected_feature_names = [feature[0] for feature in selected_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FsyLnuLQ9K-7",
   "metadata": {
    "id": "FsyLnuLQ9K-7"
   },
   "source": [
    "TESTING THE NEW IMPORTANT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1vO2GunT87Y1",
   "metadata": {
    "id": "1vO2GunT87Y1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9089292902568412\n"
     ]
    }
   ],
   "source": [
    "# Utilize the selected features\n",
    "X_train_selected = Xtrain[selected_feature_names]\n",
    "X_test_selected = Xtest[selected_feature_names]\n",
    "\n",
    "# Initializing and train a new model with selected features\n",
    "forest = RandomForestRegressor(n_estimators=250, random_state=42)\n",
    "forest.fit(X_train_selected, Ytrain)\n",
    "\n",
    "# Make predictions with the new model\n",
    "y_pred_selected = forest.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the new model's performance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse_selected = np.sqrt(mean_squared_error(Ytest, y_pred_selected))\n",
    "print(rmse_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7qprExeKPx9P",
   "metadata": {
    "id": "7qprExeKPx9P"
   },
   "source": [
    "CROSS-VALIDATION AND FINETUNING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "zCITRQUlEQ6I",
   "metadata": {
    "id": "zCITRQUlEQ6I"
   },
   "outputs": [],
   "source": [
    "#selectin random forest because it gave te least rmse and highest test score.\n",
    "rf_model = {\n",
    "    'name': 'RandomForestRegressor',\n",
    "    'model': RandomForestRegressor(),\n",
    "    'params': {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'max_depth': [ 10, 20,30],\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0b28a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving a scaler model for the flask deployment\n",
    "import pickle\n",
    "model=StandardScaler()\n",
    "filename=r'C:\\Users\\hp\\Documents\\TEXT BOOKS\\year 3_sem2\\jupyternotebooks\\scaler.pkl' \n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "i09aMNXM3Wss",
   "metadata": {
    "id": "i09aMNXM3Wss"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "GsDf22GSAI9T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GsDf22GSAI9T",
    "outputId": "a112c3fe-e7f3-41df-8a81-688fe83cd867",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RandomForestRegressor:\n",
      "\n",
      "Best Parameters: {'max_depth': 30, 'n_estimators': 150}\n",
      "Best  MSE: -0.732413300240451\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to perform GridSearchCV and return best model and results\n",
    "def perform_grid_search(model_config, Xtrain, Ytrain):\n",
    "    grid_search = GridSearchCV(model_config['model'], model_config['params'], cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(Xtrain, Ytrain)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "\n",
    "    return best_params, best_score, best_estimator\n",
    "\n",
    "# Assuming Xtrain and Ytrain are already defined\n",
    "\n",
    "# Perform GridSearchCV for RandomForestRegressor\n",
    "best_params, best_score, best_rf_model = perform_grid_search(rf_model, Xtrain, Ytrain)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Results for {rf_model['name']}:\\n\")\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best  MSE: {best_score}\")\n",
    "print(\"=============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sOeGKt_DdXOW",
   "metadata": {
    "id": "sOeGKt_DdXOW"
   },
   "source": [
    "SAVING THE MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1P2CKEdYam9i",
   "metadata": {
    "id": "1P2CKEdYam9i"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "filename=r'C:\\Users\\hp\\Documents\\TEXT BOOKS\\year 3_sem2\\jupyternotebooks\\best_rf_model.pkl' \n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(best_rf_model,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "gJLn6IpOvjla",
   "metadata": {
    "id": "gJLn6IpOvjla"
   },
   "outputs": [],
   "source": [
    "overall=data22['overall']\n",
    "y_22=data22['overall']\n",
    "X_22=data22.drop(overall)\n",
    "scaler=StandardScaler()\n",
    "x_22=scaler.fit_transform(X_22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "XOiugyunvmqG",
   "metadata": {
    "id": "XOiugyunvmqG"
   },
   "outputs": [],
   "source": [
    "# load the model from disk to test\n",
    "best_rf_model = pickle.load(open(filename, 'rb'))\n",
    "y_new_pred = best_rf_model.predict(X_22[sorted_definers])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Dfa0QDKs7yyH",
   "metadata": {
    "id": "Dfa0QDKs7yyH"
   },
   "source": [
    "EVALUATING MODEL PERFORMANCE ON NEW DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7U980fn7wC2K",
   "metadata": {
    "id": "7U980fn7wC2K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on New Data: 763.9867178731876\n"
     ]
    }
   ],
   "source": [
    "new_mse = mean_squared_error(y_22[:-47], y_new_pred)\n",
    "print(f'Mean Squared Error on New Data: {new_mse}')      # te code is wrong\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff54cde5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
